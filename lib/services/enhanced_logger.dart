import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:math';
import 'package:flutter/foundation.dart';
import 'package:intl/intl.dart';
import 'package:path_provider/path_provider.dart';
import 'package:sqflite/sqflite.dart';

/// æ—¥å¿—ç­‰çº§æšä¸¾
enum LogLevel { debug, info, warn, error, critical }

/// æ—¥å¿—åˆ†ç±»æšä¸¾
enum LogCategory { system, ai, user, device, network, security, performance }

/// ç»“æ„åŒ–æ—¥å¿—æ¡ç›®
class LogEntry {
  final String id;
  final DateTime timestamp;
  final LogLevel level;
  final LogCategory category;
  final String message;
  final Map<String, dynamic> metadata;
  final String? traceId;
  final String? userId;
  final Duration? duration;

  LogEntry({
    required this.id,
    required this.timestamp,
    required this.level,
    required this.category,
    required this.message,
    this.metadata = const {},
    this.traceId,
    this.userId,
    this.duration,
  });

  Map<String, dynamic> toJson() => {
    'id': id,
    'timestamp': timestamp.toIso8601String(),
    'level': level.name,
    'category': category.name,
    'message': message,
    'metadata': jsonEncode(metadata),
    'traceId': traceId,
    'userId': userId,
    'duration': duration?.inMilliseconds,
  };

  factory LogEntry.fromJson(Map<String, dynamic> json) => LogEntry(
    id: json['id'],
    timestamp: DateTime.parse(json['timestamp']),
    level: LogLevel.values.byName(json['level']),
    category: LogCategory.values.byName(json['category']),
    message: json['message'],
    metadata: json['metadata'] != null
        ? Map<String, dynamic>.from(jsonDecode(json['metadata']))
        : {},
    traceId: json['traceId'],
    userId: json['userId'],
    duration: json['duration'] != null ? Duration(milliseconds: json['duration']) : null,
  );

  /// è·å–æ—¥å¿—ç­‰çº§å¯¹åº”çš„emoji
  String get levelEmoji {
    switch (level) {
      case LogLevel.debug:
        return 'ğŸ”';
      case LogLevel.info:
        return 'ğŸ“‹';
      case LogLevel.warn:
        return 'âš ï¸';
      case LogLevel.error:
        return 'âŒ';
      case LogLevel.critical:
        return 'ğŸš¨';
    }
  }

  /// è·å–æ—¥å¿—åˆ†ç±»å¯¹åº”çš„emoji
  String get categoryEmoji {
    switch (category) {
      case LogCategory.system:
        return 'âš™ï¸';
      case LogCategory.ai:
        return 'ğŸ¤–';
      case LogCategory.user:
        return 'ğŸ‘¤';
      case LogCategory.device:
        return 'ğŸ“±';
      case LogCategory.network:
        return 'ğŸŒ';
      case LogCategory.security:
        return 'ğŸ”’';
      case LogCategory.performance:
        return 'ğŸ“Š';
    }
  }

  /// æ ¼å¼åŒ–æ˜¾ç¤º
  String format({bool includeMetadata = false}) {
    final time = DateFormat('HH:mm:ss.SSS').format(timestamp);
    final durationStr = duration != null ? ' (${duration!.inMilliseconds}ms)' : '';
    final traceStr = traceId != null ? ' [Trace:${traceId!.substring(0, 8)}]' : '';

    var result = '$levelEmoji $categoryEmoji [$time] $message$durationStr$traceStr';

    if (includeMetadata && metadata.isNotEmpty) {
      result += '\n  Metadata: ${jsonEncode(metadata)}';
    }

    return result;
  }
}

/// å¢å¼ºçš„æ—¥å¿—ç®¡ç†å™¨
class EnhancedLogger {
  static final _instance = EnhancedLogger._internal();
  factory EnhancedLogger() => _instance;
  EnhancedLogger._internal() {
    _initDatabase();
  }

  final StreamController<LogEntry> _logStream = StreamController.broadcast();
  final List<LogEntry> _logBuffer = [];
  final int _maxBufferSize = 1000;

  String? _currentTraceId;
  String? _currentUserId;
  Database? _database;

  Stream<LogEntry> get logStream => _logStream.stream;
  List<LogEntry> get logs => List.unmodifiable(_logBuffer);

  /// åˆå§‹åŒ–æ•°æ®åº“
  Future<void> _initDatabase() async {
    try {
      final documentsDirectory = await getApplicationDocumentsDirectory();
      final path = '${documentsDirectory.path}/autoglm_logs.db';

      _database = await openDatabase(
        path,
        version: 1,
        onCreate: (Database db, int version) async {
          await db.execute('''
            CREATE TABLE logs (
              id TEXT PRIMARY KEY,
              timestamp TEXT,
              level TEXT,
              category TEXT,
              message TEXT,
              metadata TEXT,
              traceId TEXT,
              userId TEXT,
              duration INTEGER
            )
          ''');

          // åˆ›å»ºç´¢å¼•
          await db.execute('CREATE INDEX idx_timestamp ON logs(timestamp)');
          await db.execute('CREATE INDEX idx_level ON logs(level)');
          await db.execute('CREATE INDEX idx_category ON logs(category)');
          await db.execute('CREATE INDEX idx_traceId ON logs(traceId)');
        },
      );
    } catch (e) {
      debugPrint('Failed to initialize log database: $e');
    }
  }

  /// å¼€å§‹è¿½è¸ª
  void startTrace(String traceId, {String? userId}) {
    _currentTraceId = traceId;
    _currentUserId = userId;
    log(LogLevel.info, LogCategory.system, 'å¼€å§‹æ‰§è¡Œä»»åŠ¡',
        metadata: {'action': 'trace_start', 'traceId': traceId, 'userId': userId});
  }

  /// ç»“æŸè¿½è¸ª
  void endTrace({String? result}) {
    if (_currentTraceId != null) {
      log(LogLevel.info, LogCategory.system, 'ä»»åŠ¡æ‰§è¡Œå®Œæˆ',
          metadata: {'action': 'trace_end', 'result': result});
      _currentTraceId = null;
      _currentUserId = null;
    }
  }

  /// è®°å½•æ—¥å¿—
  void log(LogLevel level, LogCategory category, String message, {
    Map<String, dynamic>? metadata,
    String? traceId,
    String? userId,
    Duration? duration,
  }) {
    final entry = LogEntry(
      id: _generateId(),
      timestamp: DateTime.now(),
      level: level,
      category: category,
      message: message,
      metadata: metadata ?? {},
      traceId: traceId ?? _currentTraceId,
      userId: userId ?? _currentUserId,
      duration: duration,
    );

    _addToBuffer(entry);
    _logStream.add(entry);

    // æŒä¹…åŒ–é‡è¦æ—¥å¿—
    if (level.index >= LogLevel.warn.index) {
      _persistLog(entry);
    }

    // æ§åˆ¶å°è¾“å‡ºï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰
    if (kDebugMode) {
      debugPrint(entry.format());
    }
  }

  /// ä¾¿æ·æ–¹æ³•
  void debug(String message, {Map<String, dynamic>? metadata, LogCategory category = LogCategory.system}) {
    log(LogLevel.debug, category, message, metadata: metadata);
  }

  void info(String message, {Map<String, dynamic>? metadata, LogCategory category = LogCategory.system}) {
    log(LogLevel.info, category, message, metadata: metadata);
  }

  void warn(String message, {Map<String, dynamic>? metadata, LogCategory category = LogCategory.system}) {
    log(LogLevel.warn, category, message, metadata: metadata);
  }

  void error(String message, {Map<String, dynamic>? metadata, LogCategory category = LogCategory.system}) {
    log(LogLevel.error, category, message, metadata: metadata);
  }

  void critical(String message, {Map<String, dynamic>? metadata, LogCategory category = LogCategory.system}) {
    log(LogLevel.critical, category, message, metadata: metadata);
  }

  /// æ·»åŠ åˆ°ç¼“å†²åŒº
  void _addToBuffer(LogEntry entry) {
    _logBuffer.add(entry);
    if (_logBuffer.length > _maxBufferSize) {
      _logBuffer.removeAt(0);
    }
  }

  /// æŒä¹…åŒ–æ—¥å¿—
  Future<void> _persistLog(LogEntry entry) async {
    try {
      await _database?.insert('logs', entry.toJson());
    } catch (e) {
      debugPrint('Failed to persist log: $e');
    }
  }

  /// è¿‡æ»¤æ—¥å¿—
  List<LogEntry> filter({
    LogLevel? level,
    LogCategory? category,
    String? traceId,
    String? userId,
    DateTime? since,
    DateTime? until,
    String? searchText,
  }) {
    return _logBuffer.where((log) {
      if (level != null && log.level != level) return false;
      if (category != null && log.category != category) return false;
      if (traceId != null && log.traceId != traceId) return false;
      if (userId != null && log.userId != userId) return false;
      if (since != null && log.timestamp.isBefore(since)) return false;
      if (until != null && log.timestamp.isAfter(until)) return false;
      if (searchText != null &&
          !log.message.toLowerCase().contains(searchText.toLowerCase())) {
        return false;
      }
      return true;
    }).toList();
  }

  /// ä»æ•°æ®åº“æŸ¥è¯¢æ—¥å¿—
  Future<List<LogEntry>> queryLogs({
    LogLevel? level,
    LogCategory? category,
    String? traceId,
    DateTime? since,
    DateTime? until,
    int? limit,
    int? offset,
  }) async {
    if (_database == null) return [];

    try {
      String whereClause = '1=1';
      List<dynamic> whereArgs = [];

      if (level != null) {
        whereClause += ' AND level = ?';
        whereArgs.add(level.name);
      }
      if (category != null) {
        whereClause += ' AND category = ?';
        whereArgs.add(category.name);
      }
      if (traceId != null) {
        whereClause += ' AND traceId = ?';
        whereArgs.add(traceId);
      }
      if (since != null) {
        whereClause += ' AND timestamp >= ?';
        whereArgs.add(since.toIso8601String());
      }
      if (until != null) {
        whereClause += ' AND timestamp <= ?';
        whereArgs.add(until.toIso8601String());
      }

      final results = await _database!.query(
        'logs',
        where: whereClause,
        whereArgs: whereArgs,
        orderBy: 'timestamp DESC',
        limit: limit,
        offset: offset,
      );

      return results.map((json) => LogEntry.fromJson(json)).toList();
    } catch (e) {
      debugPrint('Failed to query logs: $e');
      return [];
    }
  }

  /// æ¸…ç©ºæ—¥å¿—
  Future<void> clearLogs() async {
    _logBuffer.clear();
    try {
      await _database?.delete('logs');
    } catch (e) {
      debugPrint('Failed to clear logs: $e');
    }
  }

  /// å¯¼å‡ºæ—¥å¿—
  Future<String> exportLogs({
    DateTime? since,
    DateTime? until,
  }) async {
    final logs = await queryLogs(since: since, until: until);
    final exportData = {
      'exportedAt': DateTime.now().toIso8601String(),
      'totalCount': logs.length,
      'logs': logs.map((log) => log.toJson()).toList(),
    };
    return jsonEncode(exportData);
  }

  /// è·å–ç»Ÿè®¡ä¿¡æ¯
  Map<String, dynamic> getStats() {
    final now = DateTime.now();
    final oneDayAgo = now.subtract(Duration(days: 1));
    final oneHourAgo = now.subtract(Duration(hours: 1));

    final recentLogs = filter(since: oneDayAgo);
    final lastHourLogs = filter(since: oneHourAgo);

    final levelCounts = <LogLevel, int>{};
    final categoryCounts = <LogCategory, int>{};

    for (final log in recentLogs) {
      levelCounts[log.level] = (levelCounts[log.level] ?? 0) + 1;
      categoryCounts[log.category] = (categoryCounts[log.category] ?? 0) + 1;
    }

    return {
      'bufferSize': _logBuffer.length,
      'last24Hours': recentLogs.length,
      'lastHour': lastHourLogs.length,
      'levelCounts': levelCounts.map((k, v) => MapEntry(k.name, v)),
      'categoryCounts': categoryCounts.map((k, v) => MapEntry(k.name, v)),
      'errorRate': recentLogs.isNotEmpty
          ? recentLogs.where((l) => l.level.index >= LogLevel.error.index).length / recentLogs.length
          : 0.0,
    };
  }

  /// ç”Ÿæˆå”¯ä¸€ID
  String _generateId() {
    return DateTime.now().millisecondsSinceEpoch.toString() +
           Random().nextInt(1000).toString().padLeft(3, '0');
  }

  /// é‡Šæ”¾èµ„æº
  void dispose() {
    _logStream.close();
    _database?.close();
  }
}

/// æ—¥å¿—åˆ†æå™¨
class LogAnalyzer {
  final EnhancedLogger _logger = EnhancedLogger();

  /// åˆ†æä»»åŠ¡æ‰§è¡Œæ€§èƒ½
  Future<TaskPerformanceReport> analyzeTaskPerformance(String traceId) async {
    final logs = _logger.filter(traceId: traceId);

    if (logs.isEmpty) {
      return TaskPerformanceReport.empty(traceId);
    }

    final startTime = logs.last.timestamp;
    final endTime = logs.first.timestamp;
    final totalDuration = endTime.difference(startTime);

    final steps = logs.where((l) => l.metadata['action'] != null).length;
    final errors = logs.where((l) => l.level.index >= LogLevel.error.index).length;
    final warnings = logs.where((l) => l.level == LogLevel.warn).length;

    final bottlenecks = _identifyBottlenecks(logs);
    final suggestions = _generateOptimizationSuggestions(logs);

    return TaskPerformanceReport(
      traceId: traceId,
      totalDuration: totalDuration,
      stepCount: steps,
      errorCount: errors,
      warningCount: warnings,
      errorRate: steps > 0 ? errors / steps : 0.0,
      bottlenecks: bottlenecks,
      suggestions: suggestions,
    );
  }

  List<String> _identifyBottlenecks(List<LogEntry> logs) {
    final bottlenecks = <String>[];

    // åˆ†æç½‘ç»œè¯·æ±‚å»¶è¿Ÿ
    final networkLogs = logs.where((l) => l.category == LogCategory.network).toList();
    for (final log in networkLogs) {
      if (log.duration != null && log.duration!.inSeconds > 5) {
        bottlenecks.add('ç½‘ç»œè¯·æ±‚å»¶è¿Ÿ: ${log.message} (${log.duration!.inSeconds}s)');
      }
    }

    // åˆ†æè®¾å¤‡æ“ä½œå»¶è¿Ÿ
    final deviceLogs = logs.where((l) => l.category == LogCategory.device).toList();
    for (final log in deviceLogs) {
      if (log.duration != null && log.duration!.inSeconds > 2) {
        bottlenecks.add('è®¾å¤‡æ“ä½œå»¶è¿Ÿ: ${log.message} (${log.duration!.inSeconds}s)');
      }
    }

    return bottlenecks;
  }

  List<String> _generateOptimizationSuggestions(List<LogEntry> logs) {
    final suggestions = <String>[];

    final errorLogs = logs.where((l) => l.level.index >= LogLevel.error.index).toList();
    if (errorLogs.length > 3) {
      suggestions.add('é”™è¯¯ç‡è¿‡é«˜ï¼Œå»ºè®®æ£€æŸ¥ä»»åŠ¡å¤æ‚åº¦æˆ–ç½‘ç»œç¯å¢ƒ');
    }

    final networkLogs = logs.where((l) => l.category == LogCategory.network).toList();
    if (networkLogs.any((l) => l.duration != null && l.duration!.inSeconds > 10)) {
      suggestions.add('ç½‘ç»œè¯·æ±‚è¶…æ—¶é¢‘ç¹ï¼Œå»ºè®®ä¼˜åŒ–ç½‘ç»œç¯å¢ƒæˆ–å¢åŠ é‡è¯•æœºåˆ¶');
    }

    return suggestions;
  }
}

/// ä»»åŠ¡æ€§èƒ½æŠ¥å‘Š
class TaskPerformanceReport {
  final String traceId;
  final Duration totalDuration;
  final int stepCount;
  final int errorCount;
  final int warningCount;
  final double errorRate;
  final List<String> bottlenecks;
  final List<String> suggestions;

  TaskPerformanceReport({
    required this.traceId,
    required this.totalDuration,
    required this.stepCount,
    required this.errorCount,
    required this.warningCount,
    required this.errorRate,
    required this.bottlenecks,
    required this.suggestions,
  });

  factory TaskPerformanceReport.empty(String traceId) => TaskPerformanceReport(
    traceId: traceId,
    totalDuration: Duration.zero,
    stepCount: 0,
    errorCount: 0,
    warningCount: 0,
    errorRate: 0.0,
    bottlenecks: [],
    suggestions: [],
  );
}